{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92df52e-da26-45bf-baf9-725e92927684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b78ee4-95d8-4c9d-aa09-3effd020d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/pj/Desktop/us-patent-phrase-to-phrase-matching/train.csv')\n",
    "eval_df = pd.read_csv('/Users/pj/Desktop/us-patent-phrase-to-phrase-matching/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec6b84d-605c-48de-a5f6-0c3bc7cca673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24612ee9-6838-46c3-9c43-cde261fffd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "anchor     0\n",
       "target     0\n",
       "context    0\n",
       "score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f0de46-caeb-4ae0-82b1-de55f2326483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  anchor  target  context  score\n",
       "0      False   False   False    False  False\n",
       "1      False   False   False    False  False\n",
       "2      False   False   False    False  False\n",
       "3      False   False   False    False  False\n",
       "4      False   False   False    False  False\n",
       "...      ...     ...     ...      ...    ...\n",
       "36468  False   False   False    False  False\n",
       "36469  False   False   False    False  False\n",
       "36470  False   False   False    False  False\n",
       "36471  False   False   False    False  False\n",
       "36472  False   False   False    False  False\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26af4d91-93ac-4ed1-8f24-2f619b92970d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         36473\n",
       "anchor     36473\n",
       "target     36473\n",
       "context    36473\n",
       "score      36473\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f33a05-594c-457c-bb49-6941896056e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         36473\n",
       "anchor       733\n",
       "target     29340\n",
       "context      106\n",
       "score          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd6e6a5-4bc7-409d-9b76-6125ad72e76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5 , 0.75, 0.25, 0.  , 1.  ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d98c98-10dd-4e06-911e-57a582686151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvjUlEQVR4nO3de1hU9b7H8c8gckkFvAGyI6Jse4s0NZUulsojKnVkZ6VG6SnSXUE7Y+ftVEhlUZR5y6NZmfYc3ZnttFI3SXhhp3gJJRXNbWVp2UBnK4xiAso6f3RYj5NWPxGdAd+v51nP4/x+31nzXWs903xas2bhsCzLEgAAAH6Tj6cbAAAAqA8ITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAZ8Pd1AQ1FdXa2DBw+qWbNmcjgcnm4HAAAYsCxLR44cUUREhHx8fvtcEqGpjhw8eFCRkZGebgMAANTCgQMHdOmll/5mDaGpjjRr1kzSzzs9KCjIw90AAAATLpdLkZGR9uf4byE01ZGar+SCgoIITQAA1DMml9ZwITgAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABX083AACS1G3s255uoV4reGmEp1sAGjzONAEAABggNAEAABggNAEAABggNAEAABjwaGjKy8vTbbfdpoiICDkcDi1btsyeq6qq0vjx4xUTE6MmTZooIiJCI0aM0MGDB93WcejQISUlJSkoKEghISFKTk7W0aNH3Wq2b9+um266SQEBAYqMjFRWVtZpvSxZskTt27dXQECAYmJitHLlyvOyzQAAoH7yaGgqLy9X586dNWvWrNPmjh07pq1bt+qpp57S1q1b9f7772vPnj36j//4D7e6pKQkFRUVKScnR8uXL1deXp5Gjx5tz7tcLvXv319RUVEqKCjQSy+9pIyMDM2dO9eu2bBhg4YPH67k5GRt27ZNiYmJSkxM1M6dO8/fxgMAgHrFYVmW5ekmJMnhcGjp0qVKTEz81ZotW7aoR48e+vbbb3XZZZdp9+7d6tixo7Zs2aLu3btLkrKzszVo0CB99913ioiI0OzZs/XEE0/I6XTKz89PkjRhwgQtW7ZMX3zxhSRp6NChKi8v1/Lly+3X6tWrl7p06aI5c+acsZeKigpVVFTYj10ulyIjI1VWVqagoKBz3R3ARYdbDpwbbjkA1I7L5VJwcLDR53e9uqaprKxMDodDISEhkqT8/HyFhITYgUmS4uLi5OPjo02bNtk1vXv3tgOTJMXHx2vPnj06fPiwXRMXF+f2WvHx8crPz//VXjIzMxUcHGwvkZGRdbWZAADAC9Wb0HT8+HGNHz9ew4cPt5Og0+lUaGioW52vr69atGghp9Np14SFhbnV1Dz+vZqa+TOZOHGiysrK7OXAgQPntoEAAMCr1Ys7gldVVemuu+6SZVmaPXu2p9uRJPn7+8vf39/TbQAAgAvE60NTTWD69ttvtXr1arfvG8PDw1VSUuJWf+LECR06dEjh4eF2TXFxsVtNzePfq6mZBwAA8Oqv52oC0969e/XJJ5+oZcuWbvOxsbEqLS1VQUGBPbZ69WpVV1erZ8+edk1eXp6qqqrsmpycHLVr107Nmze3a3Jzc93WnZOTo9jY2PO1aQAAoJ7xaGg6evSoCgsLVVhYKEnat2+fCgsLtX//flVVVemOO+7QZ599poULF+rkyZNyOp1yOp2qrKyUJHXo0EEDBgzQqFGjtHnzZq1fv16pqakaNmyYIiIiJEl33323/Pz8lJycrKKiIi1evFjTp09XWlqa3cejjz6q7OxsTZkyRV988YUyMjL02WefKTU19YLvEwAA4J08esuBtWvXqk+fPqeNjxw5UhkZGYqOjj7j89asWaNbbrlF0s83t0xNTdVHH30kHx8fDRkyRDNmzFDTpk3t+u3btyslJUVbtmxRq1at9Mgjj2j8+PFu61yyZImefPJJffPNN7rqqquUlZWlQYMGGW/L2fxkEcDpuOXAueGWA0DtnM3nt9fcp6m+IzQB54bQdG4ITUDtNNj7NAEAAHgKoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMCA1/8ZFeB84mfu54afuQO4mHCmCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwAChCQAAwIBHQ1NeXp5uu+02RUREyOFwaNmyZW7zlmUpPT1dbdq0UWBgoOLi4rR37163mkOHDikpKUlBQUEKCQlRcnKyjh496lazfft23XTTTQoICFBkZKSysrJO62XJkiVq3769AgICFBMTo5UrV9b59gIAgPrLo6GpvLxcnTt31qxZs844n5WVpRkzZmjOnDnatGmTmjRpovj4eB0/ftyuSUpKUlFRkXJycrR8+XLl5eVp9OjR9rzL5VL//v0VFRWlgoICvfTSS8rIyNDcuXPtmg0bNmj48OFKTk7Wtm3blJiYqMTERO3cufP8bTwAAKhXHJZlWZ5uQpIcDoeWLl2qxMREST+fZYqIiNBf//pXPf7445KksrIyhYWFaf78+Ro2bJh2796tjh07asuWLerevbskKTs7W4MGDdJ3332niIgIzZ49W0888YScTqf8/PwkSRMmTNCyZcv0xRdfSJKGDh2q8vJyLV++3O6nV69e6tKli+bMmWPUv8vlUnBwsMrKyhQUFFRXuwXnWbexb3u6hXqt4KURdbYujsW5qctjAVxMzubz22uvadq3b5+cTqfi4uLsseDgYPXs2VP5+fmSpPz8fIWEhNiBSZLi4uLk4+OjTZs22TW9e/e2A5MkxcfHa8+ePTp8+LBdc+rr1NTUvM6ZVFRUyOVyuS0AAKDh8trQ5HQ6JUlhYWFu42FhYfac0+lUaGio27yvr69atGjhVnOmdZz6Gr9WUzN/JpmZmQoODraXyMjIs91EAABQj3htaPJ2EydOVFlZmb0cOHDA0y0BAIDzyGtDU3h4uCSpuLjYbby4uNieCw8PV0lJidv8iRMndOjQIbeaM63j1Nf4tZqa+TPx9/dXUFCQ2wIAABourw1N0dHRCg8PV25urj3mcrm0adMmxcbGSpJiY2NVWlqqgoICu2b16tWqrq5Wz5497Zq8vDxVVVXZNTk5OWrXrp2aN29u15z6OjU1Na8DAADg0dB09OhRFRYWqrCwUNLPF38XFhZq//79cjgcGjNmjCZPnqwPP/xQO3bs0IgRIxQREWH/wq5Dhw4aMGCARo0apc2bN2v9+vVKTU3VsGHDFBERIUm6++675efnp+TkZBUVFWnx4sWaPn260tLS7D4effRRZWdna8qUKfriiy+UkZGhzz77TKmpqRd6lwAAAC/l68kX/+yzz9SnTx/7cU2QGTlypObPn69x48apvLxco0ePVmlpqW688UZlZ2crICDAfs7ChQuVmpqqfv36ycfHR0OGDNGMGTPs+eDgYK1atUopKSnq1q2bWrVqpfT0dLd7OV1//fVatGiRnnzySf3Xf/2XrrrqKi1btkxXX331BdgLAACgPvCa+zTVd9ynqX7i3kDnhvs0eQ/u0wTUToO4TxMAAIA3ITQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAY8OrQdPLkST311FOKjo5WYGCgrrzySj377LOyLMuusSxL6enpatOmjQIDAxUXF6e9e/e6refQoUNKSkpSUFCQQkJClJycrKNHj7rVbN++XTfddJMCAgIUGRmprKysC7KNAACgfvDq0PTiiy9q9uzZevXVV7V79269+OKLysrK0syZM+2arKwszZgxQ3PmzNGmTZvUpEkTxcfH6/jx43ZNUlKSioqKlJOTo+XLlysvL0+jR4+2510ul/r376+oqCgVFBTopZdeUkZGhubOnXtBtxcAAHgvX0838Fs2bNigwYMHKyEhQZJ0+eWX629/+5s2b94s6eezTNOmTdOTTz6pwYMHS5LefvtthYWFadmyZRo2bJh2796t7OxsbdmyRd27d5ckzZw5U4MGDdLLL7+siIgILVy4UJWVlZo3b578/PzUqVMnFRYW6pVXXnELVwAA4OLl1Wearr/+euXm5upf//qXJOnzzz/Xp59+qoEDB0qS9u3bJ6fTqbi4OPs5wcHB6tmzp/Lz8yVJ+fn5CgkJsQOTJMXFxcnHx0ebNm2ya3r37i0/Pz+7Jj4+Xnv27NHhw4fP2FtFRYVcLpfbAgAAGi6vPtM0YcIEuVwutW/fXo0aNdLJkyf13HPPKSkpSZLkdDolSWFhYW7PCwsLs+ecTqdCQ0Pd5n19fdWiRQu3mujo6NPWUTPXvHnz03rLzMzU008/XQdbCQAA6gOvPtP07rvvauHChVq0aJG2bt2qBQsW6OWXX9aCBQs83ZomTpyosrIyezlw4ICnWwIAAOeRV59pGjt2rCZMmKBhw4ZJkmJiYvTtt98qMzNTI0eOVHh4uCSpuLhYbdq0sZ9XXFysLl26SJLCw8NVUlLitt4TJ07o0KFD9vPDw8NVXFzsVlPzuKbml/z9/eXv73/uGwkAAOoFrz7TdOzYMfn4uLfYqFEjVVdXS5Kio6MVHh6u3Nxce97lcmnTpk2KjY2VJMXGxqq0tFQFBQV2zerVq1VdXa2ePXvaNXl5eaqqqrJrcnJy1K5duzN+NQcAAC4+Xh2abrvtNj333HNasWKFvvnmGy1dulSvvPKK/vSnP0mSHA6HxowZo8mTJ+vDDz/Ujh07NGLECEVERCgxMVGS1KFDBw0YMECjRo3S5s2btX79eqWmpmrYsGGKiIiQJN19993y8/NTcnKyioqKtHjxYk2fPl1paWme2nQAAOBlvPrruZkzZ+qpp57Sww8/rJKSEkVEROjPf/6z0tPT7Zpx48apvLxco0ePVmlpqW688UZlZ2crICDArlm4cKFSU1PVr18/+fj4aMiQIZoxY4Y9HxwcrFWrViklJUXdunVTq1atlJ6ezu0GAACAzWGdentt1JrL5VJwcLDKysoUFBTk6XZgqNvYtz3dQr1W8NKIOlsXx+Lc1OWxAC4mZ/P57dVfzwEAAHgLQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABr74jeEPFTfxqjxv4AQA8hTNNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABmoVmvr27avS0tLTxl0ul/r27XuuPQEAAHidWoWmtWvXqrKy8rTx48eP65///Oc5NwUAAOBtfM+mePv27fa/d+3aJafTaT8+efKksrOz9Yc//KHuugMAAPASZxWaunTpIofDIYfDccav4QIDAzVz5sw6aw4AAMBbnFVo2rdvnyzL0hVXXKHNmzerdevW9pyfn59CQ0PVqFGjOm8SAADA084qNEVFRUmSqqurz0szAAAA3uqsQtOp9u7dqzVr1qikpOS0EJWenn7OjQEAAHiTWoWm119/XQ899JBatWql8PBwORwOe87hcBCaAABAg1Or0DR58mQ999xzGj9+fF33AwAA4JVqdZ+mw4cP684776zrXgAAALxWrULTnXfeqVWrVtV1LwAAAF6rVl/PtW3bVk899ZQ2btyomJgYNW7c2G3+L3/5S500BwAA4C1qFZrmzp2rpk2bat26dVq3bp3bnMPhIDQBAIAGp1ahad++fXXdBwAAgFer1TVNAAAAF5tanWm6//77f3N+3rx5tWoGAADAW9UqNB0+fNjtcVVVlXbu3KnS0tIz/iFfAACA+q5WoWnp0qWnjVVXV+uhhx7SlVdeec5NAQAAeJs6u6bJx8dHaWlpmjp1al2tEgAAwGvU6YXgX331lU6cOFGXqwQAAPAKtfp6Li0tze2xZVn64YcftGLFCo0cObJOGgMAAPAmtQpN27Ztc3vs4+Oj1q1ba8qUKb/7yzoAAID6qFahac2aNXXdBwAAgFerVWiq8eOPP2rPnj2SpHbt2ql169Z10hQAAIC3qdWF4OXl5br//vvVpk0b9e7dW71791ZERISSk5N17Nixuu4RAADA42oVmtLS0rRu3Tp99NFHKi0tVWlpqT744AOtW7dOf/3rX+u6RwAAAI+rVWj6+9//rjfffFMDBw5UUFCQgoKCNGjQIL3++ut677336rTB77//Xvfcc49atmypwMBAxcTE6LPPPrPnLctSenq62rRpo8DAQMXFxWnv3r1u6zh06JCSkpIUFBSkkJAQJScn6+jRo24127dv10033aSAgABFRkYqKyurTrcDAADUb7UKTceOHVNYWNhp46GhoXX69dzhw4d1ww03qHHjxvrHP/6hXbt2acqUKWrevLldk5WVpRkzZmjOnDnatGmTmjRpovj4eB0/ftyuSUpKUlFRkXJycrR8+XLl5eVp9OjR9rzL5VL//v0VFRWlgoICvfTSS8rIyNDcuXPrbFsAAED9VqsLwWNjYzVp0iS9/fbbCggIkCT99NNPevrppxUbG1tnzb344ouKjIzUW2+9ZY9FR0fb/7YsS9OmTdOTTz6pwYMHS5LefvtthYWFadmyZRo2bJh2796t7OxsbdmyRd27d5ckzZw5U4MGDdLLL7+siIgILVy4UJWVlZo3b578/PzUqVMnFRYW6pVXXnELVwAA4OJVqzNN06ZN0/r163XppZeqX79+6tevnyIjI7V+/XpNnz69zpr78MMP1b17d915550KDQ3Vtddeq9dff92e37dvn5xOp+Li4uyx4OBg9ezZU/n5+ZKk/Px8hYSE2IFJkuLi4uTj46NNmzbZNb1795afn59dEx8frz179pz2x4lrVFRUyOVyuS0AAKDhqlVoiomJ0d69e5WZmakuXbqoS5cueuGFF/Tll1+qU6dOddbc119/rdmzZ+uqq67Sxx9/rIceekh/+ctftGDBAkmS0+mUpNO+KgwLC7PnnE6nQkND3eZ9fX3VokULt5ozrePU1/ilzMxMBQcH20tkZOQ5bi0AAPBmtfp6LjMzU2FhYRo1apTb+Lx58/Tjjz9q/PjxddJcdXW1unfvrueff16SdO2112rnzp2aM2eOx/9cy8SJE93+nIzL5SI4AQDQgNXqTNNrr72m9u3bnzbeqVMnzZkz55ybqtGmTRt17NjRbaxDhw7av3+/JCk8PFySVFxc7FZTXFxsz4WHh6ukpMRt/sSJEzp06JBbzZnWcepr/JK/v7/9y8GaBQAANFy1Ck1Op1Nt2rQ5bbx169b64YcfzrmpGjfccIN9x/Ea//rXvxQVFSXp54vCw8PDlZuba8+7XC5t2rTJviA9NjZWpaWlKigosGtWr16t6upq9ezZ067Jy8tTVVWVXZOTk6N27dq5/VIPAABcvGoVmmou+v6l9evXKyIi4pybqvHYY49p48aNev755/Xll19q0aJFmjt3rlJSUiRJDodDY8aM0eTJk/Xhhx9qx44dGjFihCIiIpSYmCjp5zNTAwYM0KhRo7R582atX79eqampGjZsmN3r3XffLT8/PyUnJ6uoqEiLFy/W9OnT3b5+AwAAF7daXdM0atQojRkzRlVVVerbt68kKTc3V+PGjavTO4Jfd911Wrp0qSZOnKhnnnlG0dHRmjZtmpKSkuyacePGqby8XKNHj1ZpaaluvPFGZWdn27dCkKSFCxcqNTVV/fr1k4+Pj4YMGaIZM2bY88HBwVq1apVSUlLUrVs3tWrVSunp6dxuAAAA2GoVmsaOHat///vfevjhh1VZWSlJCggI0Pjx4zVx4sQ6bfDWW2/Vrbfe+qvzDodDzzzzjJ555plfrWnRooUWLVr0m69zzTXX6J///Get+wQAAA1brUKTw+HQiy++qKeeekq7d+9WYGCgrrrqKvn7+9d1fwAAAF6hVqGpRtOmTXXdddfVVS8AAABeq1YXggMAAFxsCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAG6lVoeuGFF+RwODRmzBh77Pjx40pJSVHLli3VtGlTDRkyRMXFxW7P279/vxISEnTJJZcoNDRUY8eO1YkTJ9xq1q5dq65du8rf319t27bV/PnzL8AWAQCA+qLehKYtW7botdde0zXXXOM2/thjj+mjjz7SkiVLtG7dOh08eFC33367PX/y5EklJCSosrJSGzZs0IIFCzR//nylp6fbNfv27VNCQoL69OmjwsJCjRkzRg888IA+/vjjC7Z9AADAu/l6ugETR48eVVJSkl5//XVNnjzZHi8rK9Obb76pRYsWqW/fvpKkt956Sx06dNDGjRvVq1cvrVq1Srt27dInn3yisLAwdenSRc8++6zGjx+vjIwM+fn5ac6cOYqOjtaUKVMkSR06dNCnn36qqVOnKj4+/ow9VVRUqKKiwn7scrnO4x4AgAur29i3Pd1CvVXw0ghPt4DzpF6caUpJSVFCQoLi4uLcxgsKClRVVeU23r59e1122WXKz8+XJOXn5ysmJkZhYWF2TXx8vFwul4qKiuyaX647Pj7eXseZZGZmKjg42F4iIyPPeTsBAID38vrQ9M4772jr1q3KzMw8bc7pdMrPz08hISFu42FhYXI6nXbNqYGpZr5m7rdqXC6XfvrppzP2NXHiRJWVldnLgQMHarV9AACgfvDqr+cOHDigRx99VDk5OQoICPB0O278/f3l7+/v6TYAAMAF4tVnmgoKClRSUqKuXbvK19dXvr6+WrdunWbMmCFfX1+FhYWpsrJSpaWlbs8rLi5WeHi4JCk8PPy0X9PVPP69mqCgIAUGBp6nrQMAAPWJV4emfv36aceOHSosLLSX7t27Kykpyf5348aNlZubaz9nz5492r9/v2JjYyVJsbGx2rFjh0pKSuyanJwcBQUFqWPHjnbNqeuoqalZBwAAgFd/PdesWTNdffXVbmNNmjRRy5Yt7fHk5GSlpaWpRYsWCgoK0iOPPKLY2Fj16tVLktS/f3917NhR9957r7KysuR0OvXkk08qJSXF/nrtwQcf1Kuvvqpx48bp/vvv1+rVq/Xuu+9qxYoVF3aDAQCA1/Lq0GRi6tSp8vHx0ZAhQ1RRUaH4+Hj993//tz3fqFEjLV++XA899JBiY2PVpEkTjRw5Us8884xdEx0drRUrVuixxx7T9OnTdemll+qNN9741dsNAACAi0+9C01r1651exwQEKBZs2Zp1qxZv/qcqKgorVy58jfXe8stt2jbtm110SIAAGiAvPqaJgAAAG9BaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADBAaAIAADDg1aEpMzNT1113nZo1a6bQ0FAlJiZqz549bjXHjx9XSkqKWrZsqaZNm2rIkCEqLi52q9m/f78SEhJ0ySWXKDQ0VGPHjtWJEyfcatauXauuXbvK399fbdu21fz588/35gEAgHrEq0PTunXrlJKSoo0bNyonJ0dVVVXq37+/ysvL7ZrHHntMH330kZYsWaJ169bp4MGDuv322+35kydPKiEhQZWVldqwYYMWLFig+fPnKz093a7Zt2+fEhIS1KdPHxUWFmrMmDF64IEH9PHHH1/Q7QUAAN7L19MN/Jbs7Gy3x/Pnz1doaKgKCgrUu3dvlZWV6c0339SiRYvUt29fSdJbb72lDh06aOPGjerVq5dWrVqlXbt26ZNPPlFYWJi6dOmiZ599VuPHj1dGRob8/Pw0Z84cRUdHa8qUKZKkDh066NNPP9XUqVMVHx9/xt4qKipUUVFhP3a5XOdpLwAAAG/g1WeafqmsrEyS1KJFC0lSQUGBqqqqFBcXZ9e0b99el112mfLz8yVJ+fn5iomJUVhYmF0THx8vl8uloqIiu+bUddTU1KzjTDIzMxUcHGwvkZGRdbORAADAK9Wb0FRdXa0xY8bohhtu0NVXXy1Jcjqd8vPzU0hIiFttWFiYnE6nXXNqYKqZr5n7rRqXy6WffvrpjP1MnDhRZWVl9nLgwIFz3kYAAOC9vPrruVOlpKRo586d+vTTTz3diiTJ399f/v7+nm4DAABcIPXiTFNqaqqWL1+uNWvW6NJLL7XHw8PDVVlZqdLSUrf64uJihYeH2zW//DVdzePfqwkKClJgYGBdbw4AAKiHvDo0WZal1NRULV26VKtXr1Z0dLTbfLdu3dS4cWPl5ubaY3v27NH+/fsVGxsrSYqNjdWOHTtUUlJi1+Tk5CgoKEgdO3a0a05dR01NzToAAAC8+uu5lJQULVq0SB988IGaNWtmX4MUHByswMBABQcHKzk5WWlpaWrRooWCgoL0yCOPKDY2Vr169ZIk9e/fXx07dtS9996rrKwsOZ1OPfnkk0pJSbG/XnvwwQf16quvaty4cbr//vu1evVqvfvuu1qxYoXHth0AAHgXrz7TNHv2bJWVlemWW25RmzZt7GXx4sV2zdSpU3XrrbdqyJAh6t27t8LDw/X+++/b840aNdLy5cvVqFEjxcbG6p577tGIESP0zDPP2DXR0dFasWKFcnJy1LlzZ02ZMkVvvPHGr95uAAAAXHy8+kyTZVm/WxMQEKBZs2Zp1qxZv1oTFRWllStX/uZ6brnlFm3btu2sewQAABcHrz7TBAAA4C0ITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAYITQAAAAZ8Pd0AAAD4dd3Gvu3pFuqtgpdG1On6ONMEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggND0C7NmzdLll1+ugIAA9ezZU5s3b/Z0SwAAwAsQmk6xePFipaWladKkSdq6das6d+6s+Ph4lZSUeLo1AADgYYSmU7zyyisaNWqU7rvvPnXs2FFz5szRJZdconnz5nm6NQAA4GG+nm7AW1RWVqqgoEATJ060x3x8fBQXF6f8/PzT6isqKlRRUWE/LisrkyS5XK7ffa2TFT/VQccXJ5P9ezY4FuemLo8Hx+Lc8N7wHhwL72FyLGpqLMv6/RVasCzLsr7//ntLkrVhwwa38bFjx1o9evQ4rX7SpEmWJBYWFhYWFpYGsBw4cOB3swJnmmpp4sSJSktLsx9XV1fr0KFDatmypRwOhwc7Ozcul0uRkZE6cOCAgoKCPN3ORY1j4T04Ft6DY+FdGsLxsCxLR44cUURExO/WEpr+X6tWrdSoUSMVFxe7jRcXFys8PPy0en9/f/n7+7uNhYSEnM8WL6igoKB6+wZoaDgW3oNj4T04Ft6lvh+P4OBgozouBP9/fn5+6tatm3Jzc+2x6upq5ebmKjY21oOdAQAAb8CZplOkpaVp5MiR6t69u3r06KFp06apvLxc9913n6dbAwAAHkZoOsXQoUP1448/Kj09XU6nU126dFF2drbCwsI83doF4+/vr0mTJp321SMuPI6F9+BYeA+OhXe52I6Hw7JMfmMHAABwceOaJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEpovQrFmzdPnllysgIEA9e/bU5s2bf7N+yZIlat++vQICAhQTE6OVK1deoE4bnrPZ96+//rpuuukmNW/eXM2bN1dcXNxp9f/5n/8ph8PhtgwYMOB8b0aDdDbHZv78+aft94CAgAvYbcNyNvv+lltuOW3fOxwOJSQk2DW8L+pGXl6ebrvtNkVERMjhcGjZsmW/+5y1a9eqa9eu8vf3V9u2bTV//vzz3ueFRGi6yCxevFhpaWmaNGmStm7dqs6dOys+Pl4lJSVnrN+wYYOGDx+u5ORkbdu2TYmJiUpMTNTOnTsvcOf139nu+7Vr12r48OFas2aN8vPzFRkZqf79++v77793qxswYIB++OEHe/nb3/52ITanQTnbYyP9fAfkU/f7t99+ewE7bjjOdt+///77bvt9586datSoke688063Ot4X5668vFydO3fWrFmzjOr37dunhIQE9enTR4WFhRozZoweeOABffzxx+e50wuobv7cLeqLHj16WCkpKfbjkydPWhEREVZmZuYZ6++66y4rISHBbaxnz57Wn//85/PaZ0N0tvv+l06cOGE1a9bMWrBggT02cuRIa/DgwXXd6kXnbI/NW2+9ZQUHB1+g7hq2c31fTJ061WrWrJl19OhRe4z3Rd2TZC1duvQ3a8aNG2d16tTJbWzo0KFWfHz8eezswuJM00WksrJSBQUFiouLs8d8fHwUFxen/Pz8Mz4nPz/frV6S4uPjf7UeZ1abff9Lx44dU1VVlVq0aOE2vnbtWoWGhqpdu3Z66KGH9O9//7tOe2/oantsjh49qqioKEVGRmrw4MEqKiq6EO02KHXxvnjzzTc1bNgwNWnSxG2c98WFdzF8XhCaLiL/+7//q5MnT552h/OwsDA5nc4zPsfpdJ5VPc6sNvv+l8aPH6+IiAi3/ygNGDBAb7/9tnJzc/Xiiy9q3bp1GjhwoE6ePFmn/TdktTk27dq107x58/TBBx/of/7nf1RdXa3rr79e33333YVoucE41/fF5s2btXPnTj3wwANu47wvPOPXPi9cLpd++uknD3VVt/gzKkA98MILL+idd97R2rVr3S44HjZsmP3vmJgYXXPNNbryyiu1du1a9evXzxOtXhRiY2Pd/pD39ddfrw4dOui1117Ts88+68HOLi5vvvmmYmJi1KNHD7dx3hc4XzjTdBFp1aqVGjVqpOLiYrfx4uJihYeHn/E54eHhZ1WPM6vNvq/x8ssv64UXXtCqVat0zTXX/GbtFVdcoVatWunLL788554vFudybGo0btxY1157Lfv9LJ3Lvi8vL9c777yj5OTk330d3hcXxq99XgQFBSkwMNBDXdUtQtNFxM/PT926dVNubq49Vl1drdzcXLf/az5VbGysW70k5eTk/Go9zqw2+16SsrKy9Oyzzyo7O1vdu3f/3df57rvv9O9//1tt2rSpk74vBrU9Nqc6efKkduzYwX4/S+ey75csWaKKigrdc889v/s6vC8ujIvi88LTV6LjwnrnnXcsf39/a/78+dauXbus0aNHWyEhIZbT6bQsy7Luvfdea8KECXb9+vXrLV9fX+vll1+2du/ebU2aNMlq3LixtWPHDk9tQr11tvv+hRdesPz8/Kz33nvP+uGHH+zlyJEjlmVZ1pEjR6zHH3/cys/Pt/bt22d98sknVteuXa2rrrrKOn78uEe2sb4622Pz9NNPWx9//LH11VdfWQUFBdawYcOsgIAAq6ioyFObUG+d7b6vceONN1pDhw49bZz3Rd05cuSItW3bNmvbtm2WJOuVV16xtm3bZn377beWZVnWhAkTrHvvvdeu//rrr61LLrnEGjt2rLV7925r1qxZVqNGjazs7GxPbUKdIzRdhGbOnGlddtlllp+fn9WjRw9r48aN9tzNN99sjRw50q3+3Xfftf74xz9afn5+VqdOnawVK1Zc4I4bjrPZ91FRUZak05ZJkyZZlmVZx44ds/r372+1bt3aaty4sRUVFWWNGjXK/rDB2TmbYzNmzBi7NiwszBo0aJC1detWD3TdMJztf5O++OILS5K1atWq09bF+6LurFmz5oz/Dao5HiNHjrRuvvnm057TpUsXy8/Pz7riiiust95664L3fT45LMuyPHOOCwAAoP7gmiYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAAAADhCYAqCOVlZWebgHAeURoAtDgvffee4qJiVFgYKBatmypuLg4lZeXS5LmzZunTp06yd/fX23atFFqaqr9vP3792vw4MFq2rSpgoKCdNddd6m4uNiez8jIUJcuXfTGG28oOjpaAQEBkqTS0lI98MADat26tYKCgtS3b199/vnnF3ajAdQ5QhOABu2HH37Q8OHDdf/992v37t1au3atbr/9dlmWpdmzZyslJUWjR4/Wjh079OGHH6pt27aSpOrqag0ePFiHDh3SunXrlJOTo6+//lpDhw51W/+XX36pv//973r//fdVWFgoSbrzzjtVUlKif/zjHyooKFDXrl3Vr18/HTp06EJvPoA65LAsy/J0EwBwvmzdulXdunXTN998o6ioKLe5P/zhD7rvvvs0efLk056Xk5OjgQMHat++fYqMjJQk7dq1S506ddLmzZt13XXXKSMjQ88//7y+//57tW7dWpL06aefKiEhQSUlJfL397fX17ZtW40bN06jR48+j1sL4Hzy9XQDAHA+de7cWf369VNMTIzi4+PVv39/3XHHHaqqqtLBgwfVr1+/Mz5v9+7dioyMtAOTJHXs2FEhISHavXu3rrvuOklSVFSUHZgk6fPPP9fRo0fVsmVLt/X99NNP+uqrr87DFgK4UAhNABq0Ro0aKScnRxs2bNCqVas0c+ZMPfHEE8rNza2T9Tdp0sTt8dGjR9WmTRutXbv2tNqQkJA6eU0AnkFoAtDgORwO3XDDDbrhhhuUnp6uqKgo5eTk6PLLL1dubq769Olz2nM6dOigAwcO6MCBA25fz5WWlqpjx46/+lpdu3aV0+mUr6+vLr/88vO1SQA8gNAEoEHbtGmTcnNz1b9/f4WGhmrTpk368ccf1aFDB2VkZOjBBx9UaGioBg4cqCNHjmj9+vV65JFHFBcXp5iYGCUlJWnatGk6ceKEHn74Yd18883q3r37r75eXFycYmNjlZiYqKysLP3xj3/UwYMHtWLFCv3pT3/6zecC8G6EJgANWlBQkPLy8jRt2jS5XC5FRUVpypQpGjhwoCTp+PHjmjp1qh5//HG1atVKd9xxh6Sfz0598MEHeuSRR9S7d2/5+PhowIABmjlz5m++nsPh0MqVK/XEE0/ovvvu048//qjw8HD17t1bYWFh5317AZw//HoOAADAAPdpAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMPB/f1pd3WEw1gEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax = sns.countplot(x = \"score\", data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d87613-c638-4516-bbfe-d566ef04bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36473, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af20efaa-b0bf-45ce-8c48-956e749fa1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>473137168ebf7484</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abating</td>\n",
       "      <td>F24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>621b048d70aa8867</td>\n",
       "      <td>absorbent properties</td>\n",
       "      <td>absorbent characteristics</td>\n",
       "      <td>D01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>bc20a1c961cb073a</td>\n",
       "      <td>absorbent properties</td>\n",
       "      <td>absorption properties</td>\n",
       "      <td>D01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>e955700dffd68624</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>absorption of acid</td>\n",
       "      <td>B08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3a09aba546aac675</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>B08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36398</th>\n",
       "      <td>913141526432f1d6</td>\n",
       "      <td>wiring trough</td>\n",
       "      <td>wiring troughs</td>\n",
       "      <td>F16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36435</th>\n",
       "      <td>ee0746f2a8ecef97</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood articles</td>\n",
       "      <td>B05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36440</th>\n",
       "      <td>ecaf479135cf0dfd</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36464</th>\n",
       "      <td>8ceaa2b5c2d56250</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                anchor                     target  \\\n",
       "28     473137168ebf7484             abatement                    abating   \n",
       "158    621b048d70aa8867  absorbent properties  absorbent characteristics   \n",
       "161    bc20a1c961cb073a  absorbent properties      absorption properties   \n",
       "311    e955700dffd68624       acid absorption         absorption of acid   \n",
       "315    3a09aba546aac675       acid absorption            acid absorption   \n",
       "...                 ...                   ...                        ...   \n",
       "36398  913141526432f1d6         wiring trough             wiring troughs   \n",
       "36435  ee0746f2a8ecef97          wood article              wood articles   \n",
       "36440  ecaf479135cf0dfd          wood article             wooden article   \n",
       "36464  8ceaa2b5c2d56250          wood article               wood article   \n",
       "36468  8e1386cbefd7f245          wood article             wooden article   \n",
       "\n",
       "      context  score  \n",
       "28        F24    1.0  \n",
       "158       D01    1.0  \n",
       "161       D01    1.0  \n",
       "311       B08    1.0  \n",
       "315       B08    1.0  \n",
       "...       ...    ...  \n",
       "36398     F16    1.0  \n",
       "36435     B05    1.0  \n",
       "36440     B05    1.0  \n",
       "36464     B44    1.0  \n",
       "36468     B44    1.0  \n",
       "\n",
       "[1154 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.score==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fdd8e11-6077-4fb9-9f75-95cefe4e4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "961a7d66-9369-494c-9242-fa13aa85401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0fbf55-f757-44eb-8c8d-eadf0b084b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f0fcfd-0014-4209-a2fc-0127a67360b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2925, 0.9797, 0.0850],\n",
      "        [0.4612, 0.4320, 0.1992],\n",
      "        [0.6225, 0.2971, 0.0734],\n",
      "        [0.6088, 0.2624, 0.9190],\n",
      "        [0.7999, 0.9790, 0.2377]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f502ce8-58b1-4c1d-beb1-edd1b9dcd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0205792a-e244-4822-8f4b-f77b360d3bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1b96290d-c12c-4843-9511-76a8f44aa3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a00cf3b4-da53-4525-84b9-63933c55f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'Ġis', 'Ġmy', 'Ġname', '?']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "710447f3-a45d-4f6b-b8d9-00d0cff463d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ff5e58e-6a43-4217-8e43-e1c533fec98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def lemmatize_and_tokenize(examples):\n",
    "    # Tokenize the text data\n",
    "    tokens = [tokenizer.tokenize(example) for example in examples]\n",
    "    \n",
    "    # Lemmatize each token\n",
    "    #lemmatized_tokens = [[lemmatizer.lemmatize(token) for token in token_list] for token_list in tokens]\n",
    "    \n",
    "    # Join the lemmatized tokens into a string\n",
    "    #lemmatized_text = [' '.join(token_list) for token_list in lemmatized_tokens]\n",
    "    \n",
    "    # Encode the lemmatized text using the tokenizer\n",
    "    #encoded_output = tokenizer(lemmatized_text, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "    \n",
    "    # Get the encoded vector form of the input text\n",
    "    #input_ids = encoded_output['input_ids']\n",
    "    \n",
    "    #return {'input_ids': input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4edc6cce-189a-4113-b26b-01a6e5bee7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): \n",
    "    anchor_tok = tokenizer(x['anchor'], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "    target_tok = tokenizer(x['target'], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "    return {\n",
    "        'anchor_input_ids': anchor_tok.input_ids.squeeze(0),\n",
    "        'anchor_attention_mask': anchor_tok.attention_mask.squeeze(0),\n",
    "       'target_input_ids': target_tok.input_ids.squeeze(0),\n",
    "       'target_attention_mask': target_tok.attention_mask.squeeze(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c83084fe-68ec-48f0-970a-cb083658304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ed2495b7454bb7a9f204d446f267b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0a0e90fc-8d87-4f42-84d5-26f0dfad63c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37d61fd2272659b1',\n",
       " 'anchor': 'abatement',\n",
       " 'target': 'abatement of pollution',\n",
       " 'context': 'A47',\n",
       " 'score': 0.5,\n",
       " 'anchor_input_ids': [0,\n",
       "  873,\n",
       "  415,\n",
       "  6285,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'anchor_attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'target_input_ids': [0,\n",
       "  873,\n",
       "  415,\n",
       "  6285,\n",
       "  9,\n",
       "  6631,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'target_attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tok_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f545c250-cb6a-4773-af84-b8c2f85f8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def encode_anchor(x):\n",
    "#    anchor_embeddings = encode_phrases(x['anchor'])\n",
    " #   return {'anchor_embeddings': anchor_embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76f7dd26-1095-4b0b-9cae-aded7025fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def encode_target(x):\n",
    "#    target_embeddings = encode_phrases(x['target'])\n",
    "#    return {'target_embeddings': target_embeddings}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a607b9e7-1ac4-46b7-ade0-0441c4eddf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64db4aeda07843c3816f2131feb499db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#encoded_ds = tok_ds.map(encode_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2e8a4f7d-5914-4a3e-9b99-6bb09fbc8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614e39a82db742afada53bb7d3414d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#encoded_ds = encoded_ds.map(encode_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "211af2d7-997f-417d-ada2-9794df3dd97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'score', 'anchor_input_ids', 'anchor_attention_mask', 'target_input_ids', 'target_attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'score', 'anchor_input_ids', 'anchor_attention_mask', 'target_input_ids', 'target_attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1024b928-3d03-4239-aa30-23550fdbde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4c9fce2d-2f4a-4ef7-b9f9-38bc91a09cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27354\n",
      "9119\n"
     ]
    }
   ],
   "source": [
    "print(len(dds['train']))  # Should print a non-zero value\n",
    "print(len(dds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3700cc46-21c4-4f88-a036-bef7841b64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "print(dds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "04de2699-0a3f-4770-ae16-0799334970a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'anchor', 'target', 'context', 'score', 'anchor_input_ids', 'anchor_attention_mask', 'target_input_ids', 'target_attention_mask'],\n",
      "        num_rows: 27354\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'anchor', 'target', 'context', 'score', 'anchor_input_ids', 'anchor_attention_mask', 'target_input_ids', 'target_attention_mask'],\n",
      "        num_rows: 9119\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7f8b4e6-2b07-4363-a3e3-550781a5d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_accuracy(eval_pred):\n",
    "#    predictions, labels = eval_pred\n",
    "#    predictions = np.argmax(predictions, axis=1)\n",
    "#    return {'accuracy': (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40f62b19-0ac4-4dfc-94d0-5c32bb9d248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca07b5f3-5b8a-4441-bd11-3cfae24ecbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 8e-5\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d0f6dae-4598-40d7-80ec-bf7fd2f43f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    'outputs',\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4f5b1995-6f54-4f3b-8764-cd5fe01576b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # Pass the RobertaForSequenceClassification model\n",
    "    args=training_args,\n",
    "    train_dataset=dds['train'], eval_dataset=dds['test'], tokenizer=tokenizer\n",
    "    #compute_metrics=compute_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0bb5a495-5300-4efa-88ae-0f4e63c1681f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2177\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2179\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2870\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2869\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2870\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2871\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2866\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2850\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2848\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2849\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2850\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2851\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2852\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2853\u001b[0m )\n\u001b[1;32m   2854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/formatting/formatting.py:592\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    590\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table(table, key)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43m_query_table_with_indices_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa_subtable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/formatting/formatting.py:76\u001b[0m, in \u001b[0;36m_query_table_with_indices_mapping\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _query_table(table, indices\u001b[38;5;241m.\u001b[39mcolumn(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pylist())\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Iterable):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_query_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/formatting/formatting.py:101\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/table.py:123\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_gather\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices must be non-empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets, indices, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[0;32m--> 123\u001b[0m     \u001b[43m[\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batches\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offsets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    127\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema,\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/table.py:124\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices must be non-empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets, indices, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[1;32m    123\u001b[0m     [\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batches\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mslice(i \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets[batch_idx], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    126\u001b[0m     ],\n\u001b[1;32m    127\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema,\n\u001b[1;32m    128\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb27b4-66c0-4341-b7dc-7d754072c6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
